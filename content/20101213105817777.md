+++
title = "Vectorización"
slug = "20101213105817777"
date = "2010-12-13 10:58:00"
[taxonomies]
tema = ["articulos"]
autor = ["Víctor Manuel Jáquez Leal"]
+++

En 1966 un profesor de la Universidad de Stanford, Michael J. Flynn
propusouna clasificación para la arquitectura de computadoras conocida
como laTaxonomía de Flynn \[1\].

Esta clasificación está basada en el número concurrente de instrucciones
y enlos flujos de datos disponibles en la arquitectura:

    |---------------+--------------------+----------------------||               | Single Instruction | Multiple Instruction ||---------------+--------------------+----------------------|| Single Data   | SISD               | MISD                 || Multiple Data | SIMD               | MIMD                 ||---------------+--------------------+----------------------|

De manera general los ordenadores personales pueden considerarse como
SISD:Single Instruction, Single Data. Estos procesadores solamente
pueden hacer unaoperación sobre un valor a la vez.

Sin embargo, con la llegada del procesamiento multimedia, el mercado de
losordenadores personales comenzó a ejercer presión sobre los
fabricantes dechips para proveer de hardware más potente capaz de
reproducir audio y vídeo(actividad muy demandante de poder de cómputo),
sin afectar la sensación dedesempeño en las demás tareas.

<!-- more -->
Esta demanda significaba, en gran medida, dotar de procesamiento
paralelo alos baratos procesadores de la computación personal, ya que
para reproducirmultimedia mientras se realizan otras tareas, la
arquitectura SISD, por másvelocidad de procesamiento que adquiriera,
jamás lograría el objetivo.

La respuesta a esto, a mitad de la década de 1990, fue que las compañías
dehardware introdujeron extensiones al conjunto de instrucciones nativas
de susprocesadores. Estas extensiones son la implementación de la
arquitectura SIMDdentro de sus CPUs SISD. Ejemplos de estas extensiones
son la SSE \[2\] deIntel, la 3DNow! \[3\] de AMD y NEON en ARM \[4\].

En otras palabras, el advenimiento de la arquitectura SIMD en los
ordenadorespersonales implicó la llegada de la computación paralela al
público masivo.

Como su nombre lo indica, la arquitectura SIMD es la forma de
paralelizaciónmás básica y simple que existe, en donde la misma
operación se realiza en unconjunto de datos a la vez.

Supongamos que tenemos el siguiente pseudocódigo:

    for (i = 0; i < N; i++) {    a[i] = a[i] + b[i];}

sobre los vectores

    a = { 2, 4, 6, 8 } ; b = { 1, 3, 5, 7 }

En la arquitectura SISD el número de operaciones a realizar serían
cuatro:

    op(2) -> 3op(4) -> 7op(6) -> 11op(8) -> 15

No obstante, en la arquitectura SIMD solamente se realizaría *una*
operación:

    vop(2,4,6,8) -> { 3, 7, 11, 15 }

La misma operación se realiza simultáneamente sobre todo el vector de
datos,siendo, en este caso, cuatro veces más rápido la ejecución del
algoritmo.

En computación paralela, a este tipo de paralelización se le conoce
como*vectorización*, debido a que su ámbito de optimización es sobre
operacionesvectoriales, y por ende, en matriciales.

El procesamiento de audio y vídeo se basa casi exclusivamente en
operacionesmatriciales, como la transformada discreta de Fourier \[5\],
y es por esto quela extensiones SIMD en los procesadores de los
ordenadores personalessatisfacen las demandas de multimedia del mercado.

Como normalmente sucede, el hardware va varios pasos adelante de
software, loque provoca que los sistemas de cómputo en el mercado no
explotan todas lascapacidades del hardware disponible. Además que la
mayoría de losprogramadores pocas veces van más allá de lo que sus
compiladores y entornosde desarrollo les proveen.

En la actualidad, un área de investigación importante en el desarrollo
decompiladores, es el uso automático de las extensiones SIMD, o también
conocidacomo "vectorización automática". De esta manera el programador
no tendría queemplear una lógica distinta y una sintaxis especifica en
su código; elcompilador detectaría aquellas porciones de código
secuencial susceptibles avectorizar (vea, por ejemplo, el wiki sobre
vectorización en GCC \[6\]).

Lamentablemente la vectorización automática no garantiza que el código
sea100% optimizado para las extensiones disponibles, sino únicamente se
limita agarantizar que la dependencia y precisión de los datos no se
corrompa. Sirealmente deseamos sacarle todo el jugo a la vectorización,
el programadordeberá ensuciarse las manos con las instrucciones de bajo
nivel (vea, porejemplo, el conjunto de instrucciones de NEON para GCC
\[7\]).

Pero al haber distintos conjuntos de instrucciones para los
distintosprocesadores que el mercado maneja, aprender y utilizar cada
uno de ellosimplica un impacto en el coste del desarrollo de software.
Imaginen si tieneque escribir la misma lógica optimizada para cada CPU
objetivo ¡qué tremendatontería!

Una de las alternativas para solucionar este problema, sobre todo si
lasporciones de código a vectorizar son muy específicas y
claramenteidentificadas, es ORC \[8\].

ORC es un compilador que, de manera diferente a lo acostumbrado, opera
através de una biblioteca de software. El lenguaje que este compilador
procesaes un tipo de lenguaje ensamblador genérico que opera sobre
arreglos de datos(nuestros vectores famosos).

Como indica Eric Raymond en su libro Art of the Unix Programming \[9\],
una delas reglas de la programación es la "regla de la generación":
escribeprogramas que escriban programas \[10\], ORC es una herramienta
para seguir esteprincipio.

Nuestro programa generará, en tiempo de ejecución, el código en
elensamblador de ORC. Luego, utilizando la biblioteca de ORC, le
indicamos que compile dicho códigoauto-generado ¡también en tiempo de
ejecución! y finalmente lo ejecute.

De esta manera, nuestro código podrá funcionar de manera optimizada para
todaslas extensiones SIMD soportadas por ORC, aunque nosotros solamente
hayamosaprendido el lenguaje genérico de ORC.

Varios elementos de GStreamer, por ejemplo, utilizan ORC para optimizar
susoperación, como por ejemplo el re-escalado de vídeo y el re-muestreo
de audio.

1.http://en.wikipedia.org/wiki/Flynn%27s_taxonomy  
2. http://en.wikipedia.org/wiki/Streaming_SIMD_Extensions  
3. http://en.wikipedia.org/wiki/3DNow!  
4.
http://en.wikipedia.org/wiki/ARM_architecture#Advanced_SIMD\_.28NEON.29  
5. http://en.wikipedia.org/wiki/Discrete_Fourier_transform  
6. http://gcc.gnu.org/wiki/VectorizationTasks  
7. http://gcc.gnu.org/onlinedocs/gcc/ARM-NEON-Intrinsics.html  
8. http://code.entropywave.com/projects/orc/  
9. http://catb.org/\~esr/writings/taoup/html/  
10. http://catb.org/\~esr/writings/taoup/html/ch01s06.html#id2878742

